alpha.vantage.api.key ="26WTKJT35SAZF6PU"

alpha.vantage.base.url ="https://www.alphavantage.co/query?"

mongodb {
  database = "stock-data-management"
  servers = ["localhost:27017"]
}



# Properties for akka.kafka.ConsumerSettings can be
# defined in this section or a configuration section with
# the same layout.
akka.kafka.consumer {
  # Tuning property of scheduled polls.
  poll-interval = 50ms

  # Tuning property of the `KafkaConsumer.poll` parameter.
  # Note that non-zero value means that blocking of the thread that
  # is executing the stage will be blocked.
  poll-timeout = 50ms

  # The stage will be await outstanding offset commit requests before
  # shutting down, but if that takes longer than this timeout it will
  # stop forcefully.
  stop-timeout = 30s

  # How long to wait for `KafkaConsumer.close`
  close-timeout = 20s

  # If offset commit requests are not completed within this timeout
  # the returned Future is completed `TimeoutException`.
  commit-timeout = 15s

  # If the KafkaConsumer can't connect to the broker the poll will be
  # aborted after this timeout. The KafkaConsumerActor will throw
  # org.apache.kafka.common.errors.WakeupException which will be ignored
  # until max-wakeups limit gets exceeded.
  wakeup-timeout = 3s

  # After exceeding maxinum wakeups the consumer will stop and the stage will fail.
  max-wakeups = 10

  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the KafkaConsumerActor. Some blocking may occur.
  use-dispatcher = "akka.kafka.default-dispatcher"

  # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
  # can be defined in this configuration section.
  kafka-clients {
    enable.auto.commit = true
    group.id = "stock-data-group1"
    max.poll.records = 100
    auto.offset.reset = "earliest"
    specific.avro.reader = false

    bootstrap.servers = "localhost:9092"
    bootstrap.servers = ${?BOOTSTRAP_SERVERS}

    security.protocol = "PLAINTEXT"
    security.protocol = ${?SECURITY_PROTOCOL}
//    ssl.truststore.location = "universal/customer360.kafka.client.truststore.jks"
//    ssl.truststore.password = "P@$$W0rd"
//    ssl.keystore.location = "universal/customer360.kafka.client.keystore.jks"
//    ssl.keystore.password = "P@$$W0rd"
//    ssl.key.password = "P@$$W0rd"

    schema.registry.url = "http://localhost:8081"
    schema.registry.url = ${?SCHEMA_REGISTRY_URL}

    key.deserializer = "org.apache.kafka.common.serialization.StringDeserializer"
    value.deserializer = "io.confluent.kafka.serializers.KafkaAvroDeserializer"
  }
}


# Properties for akka.kafka.ProducerSettings can be
# defined in this section or a configuration section with
# the same layout.
akka.kafka.producer {
  # Tuning parameter of how many sends that can run in parallel.
  parallelism = 10

  # How long to wait for `KafkaProducer.close`
  close-timeout = 60s

  # Fully qualified config path which holds the dispatcher configuration
  # to be used by the producer stages. Some blocking may occur.
  # When this value is empty, the dispatcher configured for the stream
  # will be used.
  use-dispatcher = "akka.kafka.default-dispatcher"

  # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
  # can be defined in this configuration section.
  kafka-clients {
    bootstrap.servers = "localhost:9092"
    bootstrap.servers = ${?BOOTSTRAP_SERVERS}

    security.protocol = "PLAINTEXT"
    security.protocol = ${?SECURITY_PROTOCOL}

# For ssl protocol settings
//    ssl.truststore.location = "universal/customer360.kafka.client.truststore.jks"
//    ssl.truststore.password = "P@$$W0rd"
//    ssl.keystore.location = "universal/customer360.kafka.client.keystore.jks"
//    ssl.keystore.password = "P@$$W0rd"
//    ssl.key.password = "P@$$W0rd"

    schema.registry.url = "http://localhost:8081"
    schema.registry.url = ${?SCHEMA_REGISTRY_URL}

    key.serializer = "org.apache.kafka.common.serialization.StringSerializer"
    value.serializer = "io.confluent.kafka.serializers.KafkaAvroSerializer"
  }
}
